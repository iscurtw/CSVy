{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0fec7ca",
   "metadata": {},
   "source": [
    "# XGBoost Model - Implementation\n",
    "\n",
    "## Features\n",
    "\n",
    "- **XGBoostModel**: Single-target XGBoost regressor\n",
    "- **XGBoostGoalPredictor**: Dual model for home/away goals\n",
    "- Feature importance analysis\n",
    "- SHAP value interpretation\n",
    "- Cross-validation support\n",
    "- Early stopping\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "| Parameter | Default | Range | Impact |\n",
    "|-----------|---------|-------|--------|\n",
    "| learning_rate | 0.05 | 0.01-0.3 | Lower = more trees needed |\n",
    "| n_estimators | 500 | 100-2000 | More = slower but better |\n",
    "| max_depth | 6 | 3-10 | Higher = more complex |\n",
    "| min_child_weight | 3 | 1-10 | Higher = more regularization |\n",
    "| subsample | 0.8 | 0.5-1.0 | Stochastic training |\n",
    "| colsample_bytree | 0.8 | 0.5-1.0 | Feature sampling |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a9e9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost not installed. Run: pip install xgboost\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Check XGBoost availability\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    print(f\"XGBoost version: {xgb.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Run: pip install xgboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7430fec",
   "metadata": {},
   "source": [
    "## XGBoostModel Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13222755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostModel:\n",
    "    \"\"\"\n",
    "    XGBoost regression model for hockey goal prediction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params : dict\n",
    "        XGBoost hyperparameters\n",
    "    scale_features : bool\n",
    "        Whether to standardize features\n",
    "    \"\"\"\n",
    "    \n",
    "    DEFAULT_PARAMS = {\n",
    "        'learning_rate': 0.05,\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 6,\n",
    "        'min_child_weight': 3,\n",
    "        'gamma': 0.1,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 1.0,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'tree_method': 'hist',\n",
    "    }\n",
    "    \n",
    "    def __init__(self, params=None, scale_features=False):\n",
    "        self.params = {**self.DEFAULT_PARAMS, **(params or {})}\n",
    "        self.scale_features = scale_features\n",
    "        self.scaler = None\n",
    "        self.model = None\n",
    "        self.feature_names = None\n",
    "        self.feature_importances_ = None\n",
    "        self.is_fitted = False\n",
    "        self.training_history = None\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None, early_stopping_rounds=50, verbose=False):\n",
    "        \"\"\"\n",
    "        Train the XGBoost model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Training features\n",
    "        y : pd.Series\n",
    "            Training targets\n",
    "        X_val, y_val : optional\n",
    "            Validation data for early stopping\n",
    "        \"\"\"\n",
    "        # Store feature names\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.feature_names = list(X.columns)\n",
    "        \n",
    "        # Optional scaling\n",
    "        if self.scale_features:\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            self.scaler = StandardScaler()\n",
    "            X = self.scaler.fit_transform(X)\n",
    "            if X_val is not None:\n",
    "                X_val = self.scaler.transform(X_val)\n",
    "        \n",
    "        # Create and fit model\n",
    "        self.model = xgb.XGBRegressor(**self.params)\n",
    "        \n",
    "        if X_val is not None and y_val is not None:\n",
    "            self.model.fit(\n",
    "                X, y,\n",
    "                eval_set=[(X, y), (X_val, y_val)],\n",
    "                verbose=verbose\n",
    "            )\n",
    "            self.training_history = self.model.evals_result()\n",
    "        else:\n",
    "            self.model.fit(X, y, verbose=verbose)\n",
    "        \n",
    "        # Store feature importances\n",
    "        if self.feature_names:\n",
    "            self.feature_importances_ = pd.Series(\n",
    "                self.model.feature_importances_,\n",
    "                index=self.feature_names\n",
    "            ).sort_values(ascending=False)\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict target values.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model must be fitted first\")\n",
    "        \n",
    "        if self.scale_features and self.scaler:\n",
    "            X = self.scaler.transform(X)\n",
    "        \n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"Evaluate model performance.\"\"\"\n",
    "        preds = self.predict(X)\n",
    "        return {\n",
    "            'rmse': np.sqrt(mean_squared_error(y, preds)),\n",
    "            'mae': mean_absolute_error(y, preds),\n",
    "            'r2': r2_score(y, preds)\n",
    "        }\n",
    "    \n",
    "    def plot_feature_importance(self, top_n=15):\n",
    "        \"\"\"Plot top feature importances.\"\"\"\n",
    "        if self.feature_importances_ is None:\n",
    "            raise RuntimeError(\"Model must be fitted first\")\n",
    "        \n",
    "        top_features = self.feature_importances_.head(top_n)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        top_features.sort_values().plot(kind='barh', ax=ax, color='steelblue')\n",
    "        ax.set_xlabel('Importance')\n",
    "        ax.set_title(f'Top {top_n} Feature Importances')\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training and validation loss.\"\"\"\n",
    "        if self.training_history is None:\n",
    "            raise RuntimeError(\"No training history - fit with validation set\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        for name, values in self.training_history.items():\n",
    "            for metric, scores in values.items():\n",
    "                label = f\"{name} - {metric}\"\n",
    "                ax.plot(scores, label=label)\n",
    "        \n",
    "        ax.set_xlabel('Iteration')\n",
    "        ax.set_ylabel('RMSE')\n",
    "        ax.set_title('Training History')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5626012b",
   "metadata": {},
   "source": [
    "## XGBoostGoalPredictor Class\n",
    "\n",
    "Wrapper that uses two XGBoost models to predict home and away goals separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e67caf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostGoalPredictor:\n",
    "    \"\"\"\n",
    "    High-level wrapper for predicting both home and away goals.\n",
    "    \n",
    "    Uses separate XGBoost models for home and away goals.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, params=None):\n",
    "        self.params = params or {}\n",
    "        self.home_model = XGBoostModel(params)\n",
    "        self.away_model = XGBoostModel(params)\n",
    "        self.feature_columns = None\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def fit(self, games_df, feature_columns=None):\n",
    "        \"\"\"\n",
    "        Train both models on game data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        games_df : pd.DataFrame\n",
    "            Must have home_goals, away_goals, and feature columns\n",
    "        feature_columns : list, optional\n",
    "            Columns to use as features. Auto-detected if None.\n",
    "        \"\"\"\n",
    "        # Identify feature columns\n",
    "        if feature_columns is None:\n",
    "            exclude = {'home_goals', 'away_goals', 'home_team', 'away_team', 'date', 'game_id'}\n",
    "            feature_columns = [\n",
    "                col for col in games_df.columns \n",
    "                if col not in exclude and games_df[col].dtype in ['int64', 'float64']\n",
    "            ]\n",
    "        \n",
    "        self.feature_columns = feature_columns\n",
    "        X = games_df[feature_columns]\n",
    "        \n",
    "        # Train both models\n",
    "        self.home_model.fit(X, games_df['home_goals'])\n",
    "        self.away_model.fit(X, games_df['away_goals'])\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def predict_goals(self, game):\n",
    "        \"\"\"Predict home and away goals for a single game.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model must be fitted first\")\n",
    "        \n",
    "        if isinstance(game, dict):\n",
    "            game = pd.Series(game)\n",
    "        \n",
    "        X = game[self.feature_columns].values.reshape(1, -1)\n",
    "        \n",
    "        home_pred = self.home_model.predict(X)[0]\n",
    "        away_pred = self.away_model.predict(X)[0]\n",
    "        \n",
    "        return float(home_pred), float(away_pred)\n",
    "    \n",
    "    def predict_batch(self, games_df):\n",
    "        \"\"\"Predict goals for multiple games.\"\"\"\n",
    "        X = games_df[self.feature_columns]\n",
    "        return pd.DataFrame({\n",
    "            'home_pred': self.home_model.predict(X),\n",
    "            'away_pred': self.away_model.predict(X)\n",
    "        })\n",
    "    \n",
    "    def evaluate(self, games_df):\n",
    "        \"\"\"Evaluate both models on test set.\"\"\"\n",
    "        X = games_df[self.feature_columns]\n",
    "        \n",
    "        home_metrics = self.home_model.evaluate(X, games_df['home_goals'])\n",
    "        away_metrics = self.away_model.evaluate(X, games_df['away_goals'])\n",
    "        \n",
    "        # Combined metrics\n",
    "        all_preds = np.concatenate([\n",
    "            self.home_model.predict(X),\n",
    "            self.away_model.predict(X)\n",
    "        ])\n",
    "        all_actual = np.concatenate([\n",
    "            games_df['home_goals'].values,\n",
    "            games_df['away_goals'].values\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            'home': home_metrics,\n",
    "            'away': away_metrics,\n",
    "            'combined': {\n",
    "                'rmse': np.sqrt(mean_squared_error(all_actual, all_preds)),\n",
    "                'mae': mean_absolute_error(all_actual, all_preds),\n",
    "                'r2': r2_score(all_actual, all_preds)\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9fba99",
   "metadata": {},
   "source": [
    "## Demo with Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5c3b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1000 synthetic games\n",
      "\n",
      "Home goals distribution:\n",
      "home_goals\n",
      "0      4\n",
      "1    123\n",
      "2    473\n",
      "3    358\n",
      "4     42\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic hockey game data\n",
    "np.random.seed(42)\n",
    "n_games = 1000\n",
    "\n",
    "# Create feature dataframe\n",
    "data = pd.DataFrame({\n",
    "    'home_win_pct': np.random.uniform(0.3, 0.7, n_games),\n",
    "    'away_win_pct': np.random.uniform(0.3, 0.7, n_games),\n",
    "    'home_goals_avg': np.random.uniform(2.5, 3.5, n_games),\n",
    "    'away_goals_avg': np.random.uniform(2.5, 3.5, n_games),\n",
    "    'home_goals_against_avg': np.random.uniform(2.5, 3.5, n_games),\n",
    "    'away_goals_against_avg': np.random.uniform(2.5, 3.5, n_games),\n",
    "    'home_pp_pct': np.random.uniform(0.15, 0.25, n_games),\n",
    "    'away_pp_pct': np.random.uniform(0.15, 0.25, n_games),\n",
    "    'home_pk_pct': np.random.uniform(0.75, 0.85, n_games),\n",
    "    'away_pk_pct': np.random.uniform(0.75, 0.85, n_games),\n",
    "    'home_rest_days': np.random.randint(1, 5, n_games),\n",
    "    'away_rest_days': np.random.randint(1, 5, n_games),\n",
    "})\n",
    "\n",
    "# Generate realistic goal totals\n",
    "home_advantage = 0.3\n",
    "data['home_goals'] = np.round(\n",
    "    data['home_goals_avg'] * 0.5 +\n",
    "    (4 - data['away_goals_against_avg']) * 0.5 +\n",
    "    home_advantage +\n",
    "    np.random.normal(0, 0.7, n_games)\n",
    ").clip(0, 8).astype(int)\n",
    "\n",
    "data['away_goals'] = np.round(\n",
    "    data['away_goals_avg'] * 0.5 +\n",
    "    (4 - data['home_goals_against_avg']) * 0.5 +\n",
    "    np.random.normal(0, 0.7, n_games)\n",
    ").clip(0, 8).astype(int)\n",
    "\n",
    "print(f\"Generated {n_games} synthetic games\")\n",
    "print(f\"\\nHome goals distribution:\")\n",
    "print(data['home_goals'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c8f7ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 800 games\n",
      "Test set: 200 games\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "train_size = int(0.8 * n_games)\n",
    "train_df = data[:train_size]\n",
    "test_df = data[train_size:]\n",
    "\n",
    "print(f\"Training set: {len(train_df)} games\")\n",
    "print(f\"Test set: {len(test_df)} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ff13c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train XGBoostGoalPredictor\u001b[39;00m\n\u001b[32m      2\u001b[39m predictor = XGBoostGoalPredictor({\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m4\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m200\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.1\u001b[39m\n\u001b[32m      6\u001b[39m })\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[32m     11\u001b[39m metrics = predictor.evaluate(test_df)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mXGBoostGoalPredictor.fit\u001b[39m\u001b[34m(self, games_df, feature_columns)\u001b[39m\n\u001b[32m     35\u001b[39m X = games_df[feature_columns]\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Train both models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhome_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgames_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhome_goals\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mself\u001b[39m.away_model.fit(X, games_df[\u001b[33m'\u001b[39m\u001b[33maway_goals\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     41\u001b[39m \u001b[38;5;28mself\u001b[39m.is_fitted = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mXGBoostModel.fit\u001b[39m\u001b[34m(self, X, y, X_val, y_val, early_stopping_rounds, verbose)\u001b[39m\n\u001b[32m     62\u001b[39m         X_val = \u001b[38;5;28mself\u001b[39m.scaler.transform(X_val)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Create and fit model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[43mxgb\u001b[49m.XGBRegressor(**\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     68\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.fit(\n\u001b[32m     69\u001b[39m         X, y,\n\u001b[32m     70\u001b[39m         eval_set=[(X, y), (X_val, y_val)],\n\u001b[32m     71\u001b[39m         verbose=verbose\n\u001b[32m     72\u001b[39m     )\n",
      "\u001b[31mNameError\u001b[39m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# Train XGBoostGoalPredictor\n",
    "predictor = XGBoostGoalPredictor({\n",
    "    'max_depth': 4,\n",
    "    'n_estimators': 200,\n",
    "    'learning_rate': 0.1\n",
    "})\n",
    "\n",
    "predictor.fit(train_df)\n",
    "\n",
    "# Evaluate\n",
    "metrics = predictor.evaluate(test_df)\n",
    "\n",
    "print(\"\\nðŸ“Š Test Set Performance\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"\\nHome Goals:\")\n",
    "print(f\"  RMSE: {metrics['home']['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {metrics['home']['mae']:.4f}\")\n",
    "print(f\"  RÂ²:   {metrics['home']['r2']:.4f}\")\n",
    "\n",
    "print(f\"\\nAway Goals:\")\n",
    "print(f\"  RMSE: {metrics['away']['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {metrics['away']['mae']:.4f}\")\n",
    "print(f\"  RÂ²:   {metrics['away']['r2']:.4f}\")\n",
    "\n",
    "print(f\"\\nCombined:\")\n",
    "print(f\"  RMSE: {metrics['combined']['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {metrics['combined']['mae']:.4f}\")\n",
    "print(f\"  RÂ²:   {metrics['combined']['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "fig = predictor.home_model.plot_feature_importance(top_n=10)\n",
    "plt.title('Feature Importance (Home Goals Model)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f77ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual scatter plot\n",
    "predictions = predictor.predict_batch(test_df)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Home goals\n",
    "axes[0].scatter(test_df['home_goals'], predictions['home_pred'], alpha=0.5)\n",
    "axes[0].plot([0, 8], [0, 8], 'r--', label='Perfect prediction')\n",
    "axes[0].set_xlabel('Actual Home Goals')\n",
    "axes[0].set_ylabel('Predicted Home Goals')\n",
    "axes[0].set_title('Home Goals: Predicted vs Actual')\n",
    "axes[0].legend()\n",
    "\n",
    "# Away goals\n",
    "axes[1].scatter(test_df['away_goals'], predictions['away_pred'], alpha=0.5)\n",
    "axes[1].plot([0, 8], [0, 8], 'r--', label='Perfect prediction')\n",
    "axes[1].set_xlabel('Actual Away Goals')\n",
    "axes[1].set_ylabel('Predicted Away Goals')\n",
    "axes[1].set_title('Away Goals: Predicted vs Actual')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a09a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "residuals_home = test_df['home_goals'] - predictions['home_pred']\n",
    "residuals_away = test_df['away_goals'] - predictions['away_pred']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(residuals_home, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0, color='red', linestyle='--')\n",
    "axes[0].set_xlabel('Residual (Actual - Predicted)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title(f'Home Goals Residuals (mean: {residuals_home.mean():.3f})')\n",
    "\n",
    "axes[1].hist(residuals_away, bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].axvline(0, color='red', linestyle='--')\n",
    "axes[1].set_xlabel('Residual (Actual - Predicted)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title(f'Away Goals Residuals (mean: {residuals_away.mean():.3f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e12040",
   "metadata": {},
   "source": [
    "## Single Game Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae589eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict a single game\n",
    "sample_game = {\n",
    "    'home_win_pct': 0.65,\n",
    "    'away_win_pct': 0.45,\n",
    "    'home_goals_avg': 3.2,\n",
    "    'away_goals_avg': 2.8,\n",
    "    'home_goals_against_avg': 2.5,\n",
    "    'away_goals_against_avg': 3.0,\n",
    "    'home_pp_pct': 0.22,\n",
    "    'away_pp_pct': 0.18,\n",
    "    'home_pk_pct': 0.82,\n",
    "    'away_pk_pct': 0.78,\n",
    "    'home_rest_days': 2,\n",
    "    'away_rest_days': 1,\n",
    "}\n",
    "\n",
    "home_pred, away_pred = predictor.predict_goals(sample_game)\n",
    "\n",
    "print(\"ðŸ’ Game Prediction\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Home team predicted goals: {home_pred:.2f}\")\n",
    "print(f\"Away team predicted goals: {away_pred:.2f}\")\n",
    "print(f\"\\nPredicted winner: {'Home' if home_pred > away_pred else 'Away'} team\")\n",
    "print(f\"Expected total goals: {home_pred + away_pred:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae051b7",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('../output/models', exist_ok=True)\n",
    "\n",
    "# Save both models\n",
    "predictor.home_model.model.save_model('../output/models/xgboost_home.json')\n",
    "predictor.away_model.model.save_model('../output/models/xgboost_away.json')\n",
    "\n",
    "print(\" Models saved to ../output/models/\")\n",
    "print(\"   - xgboost_home.json\")\n",
    "print(\"   - xgboost_away.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e552c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The XGBoost model provides:\n",
    "\n",
    "1. **High accuracy** - Industry-standard gradient boosting\n",
    "2. **Feature importance** - Understand what drives predictions\n",
    "3. **Flexibility** - Many hyperparameters to tune\n",
    "4. **Speed** - Histogram-based training is very fast\n",
    "5. **Regularization** - Built-in L1/L2 regularization\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- See `training/train_xgboost.ipynb` for hyperparameter tuning\n",
    "- See `validation/validate_xgboost.ipynb` for comprehensive testing\n",
    "- Import from `utils.xgboost_model` for production use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
